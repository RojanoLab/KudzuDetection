{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Vh0hNHPiqEA2",
   "metadata": {
    "id": "Vh0hNHPiqEA2"
   },
   "source": [
    "# Download Images using the Google Street View API\n",
    "In this notebook, we download images where the dataset says its supposed to be.\n",
    "\n",
    "Before running the code, make sure to download the following files to your Google Drive:\n",
    "[/excel file path](https://)\n",
    "\n",
    "This file contains the coordiantes of 20% of the points where the kudzu plant is supposed to be. The first 10% depend of the gHM and the other 10% depends of TWI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EtL4KLYeh78h",
   "metadata": {
    "id": "EtL4KLYeh78h"
   },
   "source": [
    "## 1. Data preprocesisng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91bc5be-324f-4cfc-96b8-f9b0253baf62",
   "metadata": {
    "id": "himFAp47jPtc"
   },
   "source": [
    "## 1.1 Install utm library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Y8UOOVaIinZ7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8UOOVaIinZ7",
    "outputId": "29306e66-ba9e-4a69-f717-2d4bedeb6370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utm in /home/student/Desktop/KudzuClassification/kudzu/lib/python3.8/site-packages (0.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# If using Windows run this\n",
    "!pip install utm\n",
    "\n",
    "# If using MacOS run \"conda install -c conda-forge utm\" in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00824473",
   "metadata": {
    "id": "00824473"
   },
   "outputs": [],
   "source": [
    "# using Python\n",
    "import requests\n",
    "import utm\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4afdd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_directory = \"/home/student/Desktop/KudzuClassification/ObjectDetection\"\n",
    "output_dir = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mkFqx33agbN4",
   "metadata": {
    "id": "mkFqx33agbN4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined path: /home/student/Desktop/KudzuClassification/ObjectDetection/output\n"
     ]
    }
   ],
   "source": [
    "# Join paths\n",
    "output_folder = os.path.join(your_directory, output_dir)\n",
    "print(\"Joined path:\", output_folder)\n",
    "\n",
    "# Create output folder if it doesn't exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09878be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined path: /home/student/Desktop/KudzuClassification/ObjectDetection/gps_twi_ghm.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = 'gps_twi_ghm.xlsx'\n",
    "file_path = os.path.join(your_directory, file_name)\n",
    "print(\"Joined path:\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ltF05jqV7u",
   "metadata": {
    "id": "98ltF05jqV7u"
   },
   "source": [
    "Use pandas to read a EXCEL file named `sampling_1.5percent_basedon_ghM_or_TWI.xlsx` into a DataFrame called `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d895771c",
   "metadata": {
    "id": "d895771c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               X          Y       gHM       TWI\n",
      "0     -86.060254  37.201708  0.000000  7.725325\n",
      "1     -80.328543  38.294871  0.000000  6.619407\n",
      "2     -83.486841  35.518393  0.000000  6.786229\n",
      "3     -83.662781  35.555762  0.000000  4.754903\n",
      "4     -83.331794  35.708465  0.000000  4.955486\n",
      "...          ...        ...       ...       ...\n",
      "24085 -84.408286  33.731479  0.952147  6.811067\n",
      "24086 -95.358267  29.764465  0.953498  4.499810\n",
      "24087 -83.920285  35.967406  0.954781  5.097647\n",
      "24088 -83.920285  35.967406  0.954781  5.097647\n",
      "24089 -73.934428  40.743897  0.955685  6.394989\n",
      "\n",
      "[24090 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# All Data Dataframe\n",
    "data_df  = pd.read_excel(file_path, sheet_name='all_data') \n",
    "data_df.to_numpy()\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "DGuKMjRrN73H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGuKMjRrN73H",
    "outputId": "c2a8d16e-47ff-42d2-eab6-f15f4fd75aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               X          Y       gHM       TWI\n",
      "0     -86.060254  37.201708  0.000000  7.725325\n",
      "1     -80.328543  38.294871  0.000000  6.619407\n",
      "2     -83.486841  35.518393  0.000000  6.786229\n",
      "3     -83.662781  35.555762  0.000000  4.754903\n",
      "4     -83.331794  35.708465  0.000000  4.955486\n",
      "...          ...        ...       ...       ...\n",
      "24085 -84.408286  33.731479  0.952147  6.811067\n",
      "24086 -95.358267  29.764465  0.953498  4.499810\n",
      "24087 -83.920285  35.967406  0.954781  5.097647\n",
      "24088 -83.920285  35.967406  0.954781  5.097647\n",
      "24089 -73.934428  40.743897  0.955685  6.394989\n",
      "\n",
      "[24090 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = data_df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efa95a15-3bf2-4b1a-baf9-b5b9838e6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "851aafb6-3b5e-439e-ad9b-443ce9625d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Y         X\n",
      "0     32.22668 -84.71198\n",
      "1     40.38670 -73.98484\n",
      "2     35.17294 -79.38491\n",
      "3     35.01225 -79.52738\n",
      "4     34.89793 -79.58489\n",
      "...        ...       ...\n",
      "6202  35.05172 -83.20240\n",
      "6203  34.00546 -84.35153\n",
      "6204  31.52195 -83.42056\n",
      "6205  33.97158 -83.36531\n",
      "6206  31.22127 -82.34601\n",
      "\n",
      "[6207 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "new_data = new_data.rename(columns={'Latitude': 'Y', 'Longitude': 'X'})\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1651c9e8-799e-4384-b5cd-65036c6d3a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               X          Y  gHM       TWI\n",
      "0     -86.060254  37.201708  0.0  7.725325\n",
      "1     -86.060254  37.201708  0.0  7.725325\n",
      "2     -80.328543  38.294871  0.0  6.619407\n",
      "3     -83.486841  35.518393  0.0  6.786229\n",
      "4     -83.662781  35.555762  0.0  4.754903\n",
      "...          ...        ...  ...       ...\n",
      "30292 -83.202400  35.051720  NaN       NaN\n",
      "30293 -84.351530  34.005460  NaN       NaN\n",
      "30294 -83.420560  31.521950  NaN       NaN\n",
      "30295 -83.365310  33.971580  NaN       NaN\n",
      "30296 -82.346010  31.221270  NaN       NaN\n",
      "\n",
      "[30297 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df, new_data, on=['X', 'Y'], how='outer')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ca14947-51d1-4dc5-8fb4-291906237e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               X          Y  gHM       TWI\n",
      "0     -86.060254  37.201708  0.0  7.725325\n",
      "1     -80.328543  38.294871  0.0  6.619407\n",
      "2     -83.486841  35.518393  0.0  6.786229\n",
      "3     -83.662781  35.555762  0.0  4.754903\n",
      "4     -83.331794  35.708465  0.0  4.955486\n",
      "...          ...        ...  ...       ...\n",
      "28089 -83.202400  35.051720  NaN       NaN\n",
      "28090 -84.351530  34.005460  NaN       NaN\n",
      "28091 -83.420560  31.521950  NaN       NaN\n",
      "28092 -83.365310  33.971580  NaN       NaN\n",
      "28093 -82.346010  31.221270  NaN       NaN\n",
      "\n",
      "[28094 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on all columns\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Reset index if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f6ac0f7-ef0c-4fa4-9152-e8fe09c823f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing or invalid locations: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing or NaN values in your DataFrame for location coordinates\n",
    "missing_rows = df[df[['Y', 'X']].isnull().any(axis=1)]\n",
    "print(f\"Missing or invalid locations: {len(missing_rows)}\")\n",
    "\n",
    "# Optionally, you can drop rows with missing or NaN values to ensure complete processing\n",
    "df_cleaned = df.dropna(subset=['Y', 'X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n4nRHbEH-68i",
   "metadata": {
    "id": "n4nRHbEH-68i"
   },
   "source": [
    "## We joined both data sets into one and now we can proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tk2V_7aEqqDR",
   "metadata": {
    "id": "tk2V_7aEqqDR"
   },
   "source": [
    "You access coordinates from the DataFrame `df` using the `loc` method, e.g., `df.loc[0, \"X\"].`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "777f2f02-f3df-4ae8-8ac1-499a3a66cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5400bdd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5400bdd8",
    "outputId": "d7a9ede7-78e7-4445-946c-6c13658a4e6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-86.0602542323586"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, \"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "kW-XauVugC3Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kW-XauVugC3Q",
    "outputId": "ac50db79-020d-44ab-f6df-aae8945417e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.2017078478203"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, \"Y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utGP2hC0q1ro",
   "metadata": {
    "id": "utGP2hC0q1ro"
   },
   "source": [
    "You define the base URL for metadata and picture requests to the Google Street View API.\n",
    "You set your API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0436c061",
   "metadata": {
    "id": "0436c061"
   },
   "outputs": [],
   "source": [
    "ind=6\n",
    "meta_base = 'https://maps.googleapis.com/maps/api/streetview/metadata?'\n",
    "pic_base = 'https://maps.googleapis.com/maps/api/streetview?'\n",
    "#api_key = 'your_api_key_goes_here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O6_Wv8RuHHTO",
   "metadata": {
    "id": "O6_Wv8RuHHTO"
   },
   "source": [
    "Create an output folder inside our project folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NiU3f7u4fDfR",
   "metadata": {
    "id": "NiU3f7u4fDfR"
   },
   "source": [
    "Code for downloading images. It checks teh status of the metadata of the image to only download the imaegs with `status = 'ok'` as  images with other status don't have imagenery. Documentation: https://developers.google.com/maps/documentation/streetview/metadata#status-codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77602382-d066-4191-b24b-05b1f8b0419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your views\n",
    "views = [0, 90, 180, 270]\n",
    "\n",
    "# Define image counter\n",
    "img_count = 0\n",
    "valid_img_count = 0\n",
    "\n",
    "# Set the path for checkpoint file\n",
    "checkpoint_file = 'image_status_checkpoint.csv'\n",
    "\n",
    "# Load the already processed locations (if exists)\n",
    "processed_images = set()\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    with open(checkpoint_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            latitude, longitude, view, status = row[:4]\n",
    "            processed_images.add((latitude, longitude, view))\n",
    "            img_count += 1  # Increment total image count\n",
    "            if status == \"OK\":\n",
    "                valid_img_count += 1  # Increment valid image count for \"OK\" status images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f2b1b-52f7-4788-b3a4-0f54550a253d",
   "metadata": {},
   "source": [
    "### Check for what locations are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b9f895a-e229-495c-b1c7-6d68e5be61fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112376\n"
     ]
    }
   ],
   "source": [
    "print(len(df)*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "829b1c87-1db0-4ca3-9f47-1ede7f51e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_count = 112377\n",
      "valid_img_count = 41894\n"
     ]
    }
   ],
   "source": [
    "print(f'img_count = {img_count}')\n",
    "print(f'valid_img_count = {valid_img_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf29420-53c9-4906-8584-c0ff75338612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the checkpoint file once, and use append mode to write every processed point\n",
    "with open(checkpoint_file, 'a', newline='') as checkpoint:\n",
    "    checkpoint_writer = csv.writer(checkpoint)\n",
    "\n",
    "    # Loop through your DataFrame\n",
    "    for ind, row in df.iterrows():\n",
    "        for view in views:\n",
    "            latitude = df.loc[ind, 'Y']\n",
    "            longitude = df.loc[ind, 'X']\n",
    "            location = f\"{latitude},{longitude}\"\n",
    "\n",
    "            # Skip if this image was already processed\n",
    "            if (str(latitude), str(longitude), str(view)) in processed_images:\n",
    "                #print(f\"Skipping already processed image {latitude}_{longitude}_{view}\")\n",
    "                continue\n",
    "\n",
    "            img_count += 1  # Increment total image count for each new image\n",
    "\n",
    "            # Define metadata request parameters\n",
    "            meta_params = {'key': api_key, 'location': location}\n",
    "\n",
    "            # Make metadata request\n",
    "            meta_response = requests.get(meta_base, params=meta_params)\n",
    "\n",
    "            # Initialize pic_response to None\n",
    "            pic_response = None\n",
    "            status = \"UNKNOWN\"  # Default status if no metadata is received\n",
    "\n",
    "            try:\n",
    "                # Check if metadata request was successful\n",
    "                if meta_response.status_code == 200:\n",
    "                    meta_data = meta_response.json()\n",
    "                    status = meta_data.get('status', 'UNKNOWN')  # Get status, or default to 'UNKNOWN'\n",
    "                    print(f\"{img_count}_Image_{latitude}_{longitude}_{view} Status: {status}\")\n",
    "\n",
    "                    # Only download and save images if status is \"OK\"\n",
    "                    if status == \"OK\":\n",
    "                        # Define picture request parameters\n",
    "                        pic_params = {\n",
    "                            'key': api_key,\n",
    "                            'location': location,\n",
    "                            'heading': view,\n",
    "                            'size': \"512x512\",\n",
    "                            'fov': \"120\",\n",
    "                        }\n",
    "\n",
    "                        # Make picture request\n",
    "                        pic_response = requests.get(pic_base, params=pic_params)\n",
    "\n",
    "                        # Check if picture request was successful\n",
    "                        if pic_response.status_code == 200:\n",
    "                            # Define the image filename based on the coordinates\n",
    "                            valid_img_count += 1\n",
    "                            image_filename = f\"{output_folder}/image_{latitude}_{longitude}_{view}.jpg\"\n",
    "\n",
    "                            # Save the downloaded image with the coordinates as the filename\n",
    "                            with open(image_filename, 'wb') as file:\n",
    "                                file.write(pic_response.content)\n",
    "                            print(f\"{valid_img_count}_Image saved: {image_filename}\")\n",
    "                        else:\n",
    "                            print(f\"Error downloading image for location: {location}_{view}\")\n",
    "                else:\n",
    "                    print(f\"Error fetching metadata for location: {location}_{view}\")\n",
    "\n",
    "                # Write the status of every image (whether \"OK\" or not)\n",
    "                checkpoint_writer.writerow([latitude, longitude, view, status])\n",
    "                checkpoint.flush()  # Ensure data is immediately written to file\n",
    "\n",
    "                # Add the current image to the processed set\n",
    "                processed_images.add((str(latitude), str(longitude), str(view)))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing metadata or image: {e}\")\n",
    "\n",
    "            finally:\n",
    "                # Close the response connections\n",
    "                meta_response.close()\n",
    "                if pic_response:\n",
    "                    pic_response.close()  # Close only if pic_response was initialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec89e34e-e42f-4fe0-8183-38a86b7720a3",
   "metadata": {},
   "source": [
    "### Number of Images Checker\n",
    "If Img Count doesn't match with number of possible locations. Go to file CoordinatesCheck.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "725b6443-c2b7-4d38-a2a5-f87ed7c25b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible images = 112376\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of possible images = {len(df)*4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed6a6dee-7b2f-4d08-8fe6-9adacf3811b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of checked images = 112376\n"
     ]
    }
   ],
   "source": [
    "file_path = 'image_status_checkpoint.csv'\n",
    "check_df = pd.read_csv(file_path)\n",
    "print(f'Number of checked images = {len(check_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6IsMPhllbL8",
   "metadata": {
    "id": "b6IsMPhllbL8"
   },
   "source": [
    "### Images number checker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QHznYJvUj9Xi",
   "metadata": {
    "id": "QHznYJvUj9Xi"
   },
   "source": [
    "Define function to count files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "N1pADOZg17P1",
   "metadata": {
    "id": "N1pADOZg17P1"
   },
   "outputs": [],
   "source": [
    "def count_files(folder_path):\n",
    "    # Initialize a counter variable\n",
    "    file_count = 0\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the path is a file (not a directory)\n",
    "        if os.path.isfile(os.path.join(folder_path, file_name)):\n",
    "            file_count += 1\n",
    "\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beD1pebmkDCu",
   "metadata": {
    "id": "beD1pebmkDCu"
   },
   "source": [
    "Count how many images we obtained and how many images had ZERO_RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rUkaInsIkEg-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUkaInsIkEg-",
    "outputId": "f108079d-d4f0-45b2-965b-ce23b4c68202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good images: 41956\n",
      "Number of bad images: 70421\n",
      "Number of images: 112377\n"
     ]
    }
   ],
   "source": [
    "# Call the function to count the files\n",
    "num_ok_images = count_files(output_folder)\n",
    "num_bad_files = img_count - num_ok_images\n",
    "\n",
    "# Print the number of files in the folder\n",
    "print(f\"Number of good images: {num_ok_images}\")\n",
    "print(f\"Number of bad images: {num_bad_files}\")\n",
    "print(f\"Number of images: {num_ok_images+num_bad_files}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VahfsLaulVvF",
   "metadata": {
    "id": "VahfsLaulVvF"
   },
   "source": [
    "Check the number of images we obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ZeZzCQq-lGPE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeZzCQq-lGPE",
    "outputId": "edbb2966-2fb0-4291-be08-81f575d030e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lost points: 17605.25\n"
     ]
    }
   ],
   "source": [
    "num_points = num_bad_files/4\n",
    "print(\"Number of lost points:\", num_points)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (kudzu)",
   "language": "python",
   "name": "pythonproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
